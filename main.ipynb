{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping for 2 seconds...\n",
      "Sleeping for 2 seconds...\n",
      "69\n",
      "Sleeping for 1 seconds...\n",
      "Sleeping for 2 seconds...\n",
      "Sleeping for 1 seconds...\n",
      "Sleeping for 2 seconds...\n",
      "Sleeping for 1 seconds...\n",
      "Sleeping for 2 seconds...\n",
      "Written\n",
      "     output/scrape_links_task.json\n"
     ]
    }
   ],
   "source": [
    "from botasaurus.anti_detect_driver import AntiDetectDriver\n",
    "from botasaurus import browser\n",
    "from bs4 import BeautifulSoup\n",
    "from botasaurus.utils import write_html, write_file\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "\n",
    "addy_of_interest = \"0x089258ed79f140d73638e1bb59ea9599603f3222\"\n",
    "\n",
    "url = f\"https://dym.fyi/address/{addy_of_interest}\"\n",
    "\n",
    "def get_tx_links(driver: AntiDetectDriver):\n",
    "    page = driver.page_source\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    driver.sleep(1)\n",
    "    table = soup.find_all(\"table\", {\"class\": \"table\"})\n",
    "    all_href = table[0].find_all(\"a\")\n",
    "    step = 3\n",
    "    links = []\n",
    "\n",
    "    for i in range(0, len(all_href), step):\n",
    "        # print the text of the href\n",
    "        link = f\"https://dym.fyi/tx/{all_href[i].text}']\"\n",
    "        links.append(link)\n",
    "\n",
    "    return links\n",
    "\n",
    "\n",
    "\n",
    "def get_url(url, driver: AntiDetectDriver):\n",
    "    driver.get(url)\n",
    "    driver.sleep(2)\n",
    "    driver.refresh()\n",
    "    driver.sleep(2)\n",
    "\n",
    "\n",
    "@browser(block_images=True, reuse_driver=True, window_size=(800, 600))\n",
    "def scrape_links_task(driver: AntiDetectDriver, data):\n",
    "    links = []\n",
    "    get_url(url=url, driver=driver)\n",
    "\n",
    "\n",
    "    #getting total tx number for the address\n",
    "    tx_num = driver.get_element_or_none(\"/html/body/main/main/div[3]/div[1]/div/div[1]\")\n",
    "    tx_num = tx_num.text\n",
    "    tx_num = tx_num.split(\" \")[1]\n",
    "    tx_num = int(tx_num)\n",
    "    print(tx_num)\n",
    "    page_num = 0\n",
    "\n",
    "    #Extracting the Tx links\n",
    "    for i in range(ceil(tx_num/25)):\n",
    "        links.extend(get_tx_links(driver))\n",
    "        driver.click(\"div.col-sm-6:nth-child(2) > nav:nth-child(1) > ul:nth-child(1) > li:nth-child(4) > span:nth-child(1)\")\n",
    "        driver.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "    links = [link.strip(\"']\") for link in links]\n",
    "\n",
    "    df = pd.DataFrame(links)\n",
    "    df.to_csv(\"links.csv\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"Total Links\": len(links),\n",
    "        \"Links\": links\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scraped_links = scrape_links_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping for 2 seconds...\n",
      "Sleeping for 1 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\miniconda3\\envs\\bota\\Lib\\site-packages\\botasaurus\\decorators.py\", line 562, in run_task\n",
      "    result = func(driver, data)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mushii\\AppData\\Local\\Temp\\ipykernel_16960\\278405597.py\", line 11, in scrape_address_task\n",
      "    address = address.text\n",
      "              ^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task failed for input: None\n"
     ]
    }
   ],
   "source": [
    "@browser(block_images=True, reuse_driver=True, window_size=(800, 600))\n",
    "def scrape_address_task(driver: AntiDetectDriver, data):\n",
    "    links = pd.read_csv(\"links.csv\")\n",
    "    links = links.values.tolist()\n",
    "    for link in links:\n",
    "        driver.get(link[1])\n",
    "        driver.sleep(2)\n",
    "        driver.click(\".row-msg-summary\")\n",
    "        driver.sleep(1)\n",
    "        address = driver.get_element_or_none(\"/html/body/main/main/div[2]/div/div/div[1]/div/table/tbody/tr[2]/td/div/div/div[1]/div[1]/div[2]/div[1]/div[2]/a\")\n",
    "        address = address.text\n",
    "        print(address)\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "scrape_address_task()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bota",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
